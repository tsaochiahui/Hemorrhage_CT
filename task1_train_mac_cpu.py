import pandas as pd
from pathlib import Path
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# === 1. Dataset é¡åˆ¥ ===
class CTClassificationDataset(Dataset):
    def __init__(self, csv_file, image_root, transform=None):
        self.df = pd.read_csv(csv_file)
        self.image_root = Path(image_root)
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        folder = f"image{int(row['filename'][:4])}"   # image123
        img_path = self.image_root / folder / row["filename"]
        image = Image.open(img_path).convert("RGB")
        label = int(row["label"])
        if self.transform:
            image = self.transform(image)
        return image, label

# === 2. è¨“ç·´æµç¨‹ï¼ˆCPUå„ªåŒ–ç‰ˆï¼‰ ===
def train_task1_classification():
    # âœ… è¨­å®šæª”æ¡ˆèˆ‡è·¯å¾‘
    csv_path = "/Users/chia-huitsao/Documents/PHE-SICH-CT-IDS/Hemorrhage_CT/task1_classification_labels.csv"
    image_root = "/Users/chia-huitsao/Downloads/PHE-SICH-CT-IDS/SubdatasetC_PNG/set"

    # âœ… CPU è¨“ç·´åƒæ•¸ï¼ˆè¼ƒå°æ¨¡å‹èˆ‡ batchï¼‰
    batch_size = 4
    num_epochs = 10
    device = "cpu"

    # åˆ†å‰² train / val é›†
    df = pd.read_csv(csv_path)
    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df["label"], random_state=42)
    train_df.to_csv("train.csv", index=False)
    val_df.to_csv("val.csv", index=False)

    # å½±åƒè™•ç†ï¼ˆç°¡å–® Resize + Tensorï¼‰
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ])

    # å»ºç«‹ Dataset èˆ‡ Dataloader
    train_dataset = CTClassificationDataset("train.csv", image_root, transform)
    val_dataset = CTClassificationDataset("val.csv", image_root, transform)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0)

    # âœ… ä½¿ç”¨ ResNet18 åšåˆ†é¡
    model = models.resnet18(pretrained=True)
    model.fc = nn.Linear(model.fc.in_features, 2)  # äºŒå…ƒåˆ†é¡
    model = model.to(device)

        # âœ… æå¤±èˆ‡å„ªåŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

        # âœ… é–‹å§‹è¨“ç·´
    for epoch in range(num_epochs):
        model.train()
        train_loss = 0.0

        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        print(f"âœ… Epoch {epoch+1}, Train Loss: {train_loss / len(train_loader):.4f}")

    # âœ… å„²å­˜æ¨¡å‹
    torch.save(model.state_dict(), "/Users/chia-huitsao/Documents/PHE-SICH-CT-IDS/Hemorrhage_CT/task1_resnet18_mac.pt")
    print("ğŸ‰ è¨“ç·´å®Œæˆï¼Œæ¨¡å‹å·²å„²å­˜ç‚º task1_resnet18_mac.pt")

